{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A standard suite of tools to work with $SPRUCE$ measurements\n",
    "\n",
    "- let's get some satellite imagery figured out with `rasterio`\n",
    "- `astropy` will give appropriate motions of the sun; use the clinometer to get altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy import signal, interpolate\n",
    "import os\n",
    "import struct\n",
    "import wave\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import rasterio.mask\n",
    "import fiona\n",
    "from shapely.geometry import box, LineString, MultiPoint, Polygon\n",
    "import geopandas as gpd\n",
    "import pysolar\n",
    "import datetime as dt\n",
    "import pytz\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/dax/PythonScripts/3_GITHUB/iyore')\n",
    "import iyore\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "# audio-processing\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.utils import mediainfo\n",
    "from pydub.playback import play\n",
    "from pydub.utils import which\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "import crepe # pitch-tracking\n",
    "\n",
    "# geo-processing\n",
    "from shapely.geometry import Polygon, asPolygon, asMultiPoint, asPoint\n",
    "from shapely.affinity import rotate\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# core + technical\n",
    "import subprocess \n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import datetime as dt\n",
    "import shutil\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_SPRUCE(meas, start_time, tree):\n",
    "    \n",
    "    '''\n",
    "    Load a raw .CSV file\n",
    "    '''\n",
    "    \n",
    "    SPRUCE = pd.read_csv(meas, header=None) # read in the raw .CSV file\n",
    "    SPRUCE.columns = [\"ch1\", \"ch2\", \"ch3\", \"loop length (ms)\"] # give the columns meaningful names\n",
    "    SPRUCE = SPRUCE.replace(' NULL', np.NaN) # convert 'NULL' strings to numeric NaN\n",
    "    SPRUCE[\"loop length (ms)\"] = SPRUCE[\"loop length (ms)\"].str[:-1] # strip trailing semicolon\n",
    "    SPRUCE = SPRUCE.astype('float') # cooerce to floating point numbers\n",
    "\n",
    "    # a meaningful datetime index\n",
    "    SPRUCE.index = start_time + (SPRUCE[\"loop length (ms)\"].cumsum()/1000).apply(lambda t: dt.timedelta(seconds=t))\n",
    "    \n",
    "    SPRUCE[\"tree\"] = tree\n",
    "    \n",
    "    SPRUCE.name = tree\n",
    "\n",
    "    return SPRUCE\n",
    "\n",
    "def signal_to_wav(signal, fname, Fs):\n",
    "    \n",
    "    \"\"\"Convert a numpy array into a wav file.\n",
    "\n",
    "     Args\n",
    "     ----\n",
    "     signal : 1-D numpy array\n",
    "         An array containing the audio signal.\n",
    "     fname : str\n",
    "         Name of the audio file where the signal will be saved.\n",
    "     Fs: int\n",
    "        Sampling rate of the signal.\n",
    "\n",
    "    \"\"\"\n",
    "    data = struct.pack('<' + ('h'*len(signal)), *signal)\n",
    "    wav_file = wave.open(fname, 'wb')\n",
    "    wav_file.setnchannels(1)\n",
    "    wav_file.setsampwidth(2)\n",
    "    wav_file.setframerate(Fs)\n",
    "    wav_file.writeframes(data)\n",
    "    wav_file.close()\n",
    "    \n",
    "    print(\"complete.\")\n",
    "\n",
    "def match_target_amplitude(sound, target_dBFS):\n",
    "    \n",
    "    change_in_dBFS = target_dBFS - sound.dBFS\n",
    "    \n",
    "    return sound.apply_gain(change_in_dBFS)\n",
    "\n",
    "def combine_wav_files(in_path, out_path, out_name):\n",
    "    \n",
    "    # routing\n",
    "    in_path_wav = os.path.join(in_path, \"*.wav\")\n",
    "    out_path_name = os.path.join(os.path.join(in_path, out_path), out_name + \".wav\")\n",
    "    \n",
    "    # input\n",
    "    paths = glob.glob(in_path_wav)\n",
    "\n",
    "    stitch = AudioSegment.empty()\n",
    "    for file in paths:\n",
    "\n",
    "        sound_file = AudioSegment.from_wav(file)\n",
    "\n",
    "        stitch+=sound_file\n",
    "    \n",
    "    # output\n",
    "    stitch.export(out_path_name, format=\"wav\")\n",
    "\n",
    "    \n",
    "def audio_chunker(audio_path, silence_thresh=-36.0, min_silence=1, len_thresh=200, pad=300):\n",
    "    \n",
    "    '''\n",
    "    Wrapper to load MP3 or WAV files,\n",
    "    then use `pydub.silence.split_on_silence` to separate \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    audio_path: (str, path) the file you would like to process - can be MP3 or WAV\n",
    "    \n",
    "    silence_thresh: (float) an amplitude threshold referenced to decibels full-scale (dBFS)\n",
    "    \n",
    "    min_silence: (float) \"(in ms) minimum length of a silence to be used for\n",
    "        a split. default: 1000ms\"\n",
    "        \n",
    "    len_thresh: (float) \"\"(in ms or True/False) leave some silence at the beginning\n",
    "        and end of the chunks. Keeps the sound from sounding like it\n",
    "        is abruptly cut off.\n",
    "        When the length of the silence is less than the keep_silence duration\n",
    "        it is split evenly between the preceding and following non-silent\n",
    "        segments.\n",
    "        If True is specified, all the silence is kept, if False none is kept.\n",
    "        default: 100ms\"\n",
    "        \n",
    "    pad: (float) \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    audio_chunks: (list) of `pydub.AudioSegment` objects representing periods of \"non-silence\"\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import pydub\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "    from pydub.utils import mediainfo\n",
    "    from pydub.playback import play\n",
    "    from pydub.utils import which\n",
    "\n",
    "    AudioSegment.converter = which(\"ffmpeg\")\n",
    "    \n",
    "    # load the audio with `pydub`\n",
    "    if(audio_path[-3:] == \"wav\"):\n",
    "        sound_file = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "    elif((audio_path[-3:] == \"MP3\")|(audio_path[-3:] == \"mp3\")):\n",
    "        sound_file = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "    else:\n",
    "        print(\"there's a pydub generic 'file' version, too, you know...\")\n",
    "\n",
    "\n",
    "    # grab file info while we're at it\n",
    "    info = mediainfo(audio_path)\n",
    "\n",
    "    # break it into chunks - the thresholds here might eventually benefit \n",
    "    # from some kind of NVSPL preview, I think\n",
    "    audio_chunks = split_on_silence(sound_file, \n",
    "                                    min_silence_len=min_silence, \n",
    "                                    silence_thresh=silence_thresh,\n",
    "                                    keep_silence=pad)\n",
    "    \n",
    "    return audio_chunks\n",
    "\n",
    "\n",
    "def PCA_audio_sampler_prime(audio_path, fft_size=1024, silence_thresh=-36, min_silence=1, len_thresh=20,  \n",
    "                            pad=300, target_amplitude=-12, compute_pitch=True, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    Making a lathe on which to turn audio.\n",
    "    The premise here is to divide up the waveform (more or less dynamic) into chunks,\n",
    "    perform a re-ordination and disperal routine [that is, Principle Component Analysis, PCA]\n",
    "    and then progress through the dispersed samples using a rotor - however complex\n",
    "    \n",
    "    PCA - \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    audio_chunks = audio_chunker(audio_path, \n",
    "                                 silence_thresh=silence_thresh, \n",
    "                                 min_silence=min_silence, \n",
    "                                 len_thresh=len_thresh, \n",
    "                                 pad=pad)\n",
    "    \n",
    "    print(\"Settings produced\", len(audio_chunks), \"audio chunks\")\n",
    "    \n",
    "    # grab file info for subsequent computations\n",
    "    info = mediainfo(audio_path)\n",
    "    \n",
    "    # =================================================================\n",
    "    \n",
    "    # these are our returns\n",
    "    normalized_data = []\n",
    "    indices_out = []\n",
    "    clip_pitch = []\n",
    "    chunks_out = []\n",
    "    \n",
    "    for i, chunk in enumerate(audio_chunks):\n",
    "        \n",
    "        if target_amplitude is not None:\n",
    "            #amplify the output level to some new value\n",
    "            chunk = match_target_amplitude(chunk, target_amplitude)\n",
    "            chunks_out.append(chunk_normalized)\n",
    "\n",
    "        else:\n",
    "            chunks_out.append(chunk)\n",
    "        \n",
    "\n",
    "        # convert the `pydub` object to `numpy`\n",
    "        samples = chunk.get_array_of_samples()\n",
    "        samples = np.array(samples)\n",
    "\n",
    "        # if stereo, use the L channel only\n",
    "        if(len(samples.shape) > 1):\n",
    "            samples = samples[:, 0]\n",
    "\n",
    "        rate = int(info['sample_rate'])\n",
    "        #rate = 44100\n",
    "\n",
    "        # perform a short-time Fourier transform on the data\n",
    "        frequencies, times, Zxx = signal.stft(samples, \n",
    "                                              rate, \n",
    "                                              nfft=fft_size)\n",
    "    \n",
    "        if(verbose):\n",
    "            print(Zxx.shape, times.shape)\n",
    "\n",
    "        if(i%100 == 0):\n",
    "            print(\"chunk \", i+1)\n",
    "\n",
    "        # create the spectrogram by dropping the imaginary (phase) component of the signal\n",
    "        spectrogram = np.log(np.abs(Zxx))\n",
    "\n",
    "        if((times.shape[0] > len_thresh)):\n",
    "        #if((times.shape[0] > len_thresh)&(times.shape[0] < 80)):\n",
    "\n",
    "            if(verbose):\n",
    "\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                plt.pcolormesh(times, frequencies, spectrogram, cmap='magma')\n",
    "                plt.title(\"Chunk \"+str(i), loc=\"left\")\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "\n",
    "            if(compute_pitch):\n",
    "\n",
    "                # perform pitch detection\n",
    "                time, frequency, confidence, activation = crepe.predict(samples, rate, viterbi=False, \n",
    "                                                                        step_size=len(samples), verbose=False)\n",
    "\n",
    "                # if there is reasonable confidence, add it to the attributes\n",
    "                if(confidence > 0.1):\n",
    "                    clip_pitch.append(frequency[0])\n",
    "\n",
    "                else:\n",
    "                    clip_pitch.append(np.nan)\n",
    "\n",
    "            else:\n",
    "                clip_pitch.append(np.nan)\n",
    "\n",
    "            # then flatten the spectrogram into a vector for PCA\n",
    "            norm = spectrogram.flatten()/spectrogram.flatten().max()\n",
    "            normalized_data.append(norm)\n",
    "            indices_out.append(i)\n",
    "        \n",
    "    return chunks_out, normalized_data, indices_out, clip_pitch\n",
    "\n",
    "def polygon_coords(center, radius, n):\n",
    "    \n",
    "    # set up each coordinate\n",
    "    xs = center[0] + radius * np.cos(np.pi/n * (1 + 2 * np.arange(0, n)))\n",
    "    ys = center[1] + radius * np.sin(np.pi/n * (1 + 2 * np.arange(0, n)))\n",
    "    \n",
    "    coords = np.array([xs, ys]).T\n",
    "    \n",
    "    ngon = asPolygon(coords)\n",
    "    \n",
    "    return ngon\n",
    "\n",
    "def gold(value, operator=\"+\", repeats=1):\n",
    "    \n",
    "    '''\n",
    "    Golden ratio calculator; T A P E    M A T H\n",
    "    \n",
    "    operator\n",
    "        \"+\"  scale up\n",
    "        \"-\"  scale down\n",
    "        \n",
    "    repeats:  optional\n",
    "        otherwise, int\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    big = 1+np.sqrt(5)\n",
    "    small = 2\n",
    "    \n",
    "    \n",
    "    def up(value):\n",
    "        \n",
    "        phi_multiply = small/big - small\n",
    "        \n",
    "        value *= -phi_multiply # 1.381966%\n",
    "        return value\n",
    "    \n",
    "    def down(value):\n",
    "        \n",
    "        #phi_divide = (small - big)/big\n",
    "        phi_divide = big/small - small\n",
    "        value *= -phi_divide # 0.381966%\n",
    "        return value\n",
    "    \n",
    "    def repeat(fn, n):\n",
    "        \n",
    "        if n == 1:\n",
    "            return fn\n",
    "        else:\n",
    "            def new_fn(x):\n",
    "                return fn(repeat(fn, n-1)(x))\n",
    "\n",
    "            return new_fn\n",
    "    \n",
    "\n",
    "    if ((operator == \"+\")|(operator == 1)|(operator == True)):\n",
    "        out = repeat(up, repeats)(value)     # scale up\n",
    "        return out\n",
    "        \n",
    "    elif ((operator == \"-\")|(operator == -1)|(operator == False)):\n",
    "        out = repeat(down, repeats)(value)      # scale down\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a masked version of the Alaska 5-meter DEM for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio.open(\"/home/dax/Documents/SPATIAL/Datasets/USGS_AK5M_AK_IFSAR_2010_58.tif\") as src:\n",
    "    \n",
    "#     # create a rectangular mask\n",
    "#     mask = gpd.GeoDataFrame([], \n",
    "#                         geometry=[box(-148.984514, 63.38777, -148.948851, 63.399623)],\n",
    "#                         crs=\"EPSG:4326\")\n",
    "    \n",
    "#     mask = mask.to_crs(src.crs)\n",
    "    \n",
    "#     print(mask.geometry[0])\n",
    "    \n",
    "#     out_image, out_transform = rasterio.mask.mask(src, [mask.geometry[0]], crop=True)\n",
    "#     out_meta = src.meta\n",
    "    \n",
    "# out_meta.update({\"driver\": \"GTiff\",\n",
    "#                  \"height\": out_image.shape[1],\n",
    "#                  \"width\": out_image.shape[2],\n",
    "#                  \"transform\": out_transform})\n",
    "\n",
    "# with rasterio.open(\"/home/dax/Documents/SPATIAL/Datasets/USGS_AK5M_AK_IFSAR_2010_58_Cantwell.tif\", \"w\", **out_meta) as dest:\n",
    "#     dest.write(out_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# ras = rasterio.open(\"/home/dax/Documents/SPATIAL/Datasets/USGS_AK5M_AK_IFSAR_2010_58_Cantwell.tif\")\n",
    "\n",
    "# tree = gpd.GeoDataFrame([], geometry=[asPoint([-148.973065, 63.397140])], crs=\"epsg:4326\")\n",
    "# # tree = tree.to_crs(ras.crs)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# rasterio.plot.show(ras, cmap=\"YlGn_r\", ax=ax)\n",
    "# tree.plot(ax=ax)\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# ras.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load *every* Cantwell Rock measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPRUCE = iyore.Dataset(r\"/home/dax/Documents/ALBUM/SPRUCE/03 Field Measurements\")\n",
    "\n",
    "# # join all spruce measurements together\n",
    "# S = pd.concat([parse_SPRUCE(e.path,\n",
    "#                         dt.datetime(int(e.year), \n",
    "#                                     int(e.month), \n",
    "#                                     int(e.day), \n",
    "#                                     int(e.begin_hour), \n",
    "#                                     int(e.begin_minute)),\n",
    "#                                     e.location + \" \" + e.num) for e in SPRUCE.meas(location=\"CantwellRock\")])\n",
    "\n",
    "# # trim off the rather extreme bits\n",
    "# S.loc[:, \"ch1\":\"ch3\"] = S.loc[:, \"ch1\":\"ch3\"].mask(S.loc[:, \"ch1\":\"ch3\"].abs() > 0.2)\n",
    "\n",
    "# S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRUCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and plot raw voltage measurements from each of 3 leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wax = S.loc[\"2022-08-01 20:00:00\":\"2022-08-01 20:58:00\", :]\n",
    "\n",
    "plt.plot(wax.index, wax.ch1)\n",
    "# plt.axvline(dt.datetime(2022, 8, 1, 20, 58), ls=\"--\", color=\"magenta\")\n",
    "plt.show()\n",
    "\n",
    "wax.index\n",
    "\n",
    "# len(wax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRUCE = iyore.Dataset(r\"/home/dax/Documents/ALBUM/SPRUCE/03 Field Measurements\")\n",
    "\n",
    "# join all spruce measurements together\n",
    "S = pd.concat([parse_SPRUCE(e.path,\n",
    "                        dt.datetime(int(e.year), \n",
    "                                    int(e.month), \n",
    "                                    int(e.day), \n",
    "                                    int(e.begin_hour), \n",
    "                                    int(e.begin_minute)),\n",
    "                                    e.location + \" \" + e.num) for e in SPRUCE.meas(location=\"CantwellRock\")])\n",
    "\n",
    "S = S.sort_index()\n",
    "W = S.dropna()\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "plt.plot(W[\"loop length (ms)\"].cumsum()/1000, W.ch1, ls=\"\", marker=\"o\", ms=1, color=\"red\")\n",
    "plt.plot(W[\"loop length (ms)\"].cumsum()/1000, W.ch2, ls=\"\", marker=\"o\", ms=1, color=\"green\")\n",
    "plt.plot(W[\"loop length (ms)\"].cumsum()/1000, W.ch3, ls=\"\", marker=\"o\", ms=1, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(W.index.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W[::100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 2))\n",
    "ax[0].plot(W.ch1, W.ch2, ls=\"\", marker=\"o\", ms=1, color=\"red\")\n",
    "ax[1].plot(W.ch1, W.ch3, ls=\"\", marker=\"o\", ms=1, color=\"green\")\n",
    "ax[2].plot(W.ch2, W.ch3, ls=\"\", marker=\"o\", ms=1, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# import matplotlib.dates as dates\n",
    "# plt_dates = dates.date2num(S.index.to_pydatetime())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# ax.scatter(S.cx - S_x0, \n",
    "#            S.cy - S_y0, \n",
    "#            S.cz - S_z0, \n",
    "#            c=fader, alpha=0.1)\n",
    "\n",
    "p = ax.scatter(S.ch1, \n",
    "               S.ch2, \n",
    "               S.ch3, \n",
    "               s=2,\n",
    "               c=\"viridis\", alpha=0.1)\n",
    "\n",
    "# ax.set_xlabel(\"PC1\")\n",
    "# ax.set_ylabel(\"PC2\")\n",
    "# ax.set_zlabel(\"PC3\")\n",
    "\n",
    "# ax.view_init(elev=45, azim=30)\n",
    "\n",
    "fig.colorbar(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRUCE = iyore.Dataset(r\"/home/dax/Documents/ALBUM/SPRUCE/03 Field Measurements\")\n",
    "\n",
    "# join all spruce measurements together\n",
    "S = pd.concat([parse_SPRUCE(e.path,\n",
    "                        dt.datetime(int(e.year), \n",
    "                                    int(e.month), \n",
    "                                    int(e.day), \n",
    "                                    int(e.begin_hour), \n",
    "                                    int(e.begin_minute)),\n",
    "                                    e.location + \" \" + e.num) for e in SPRUCE.meas(location=\"CantwellRock\")])\n",
    "\n",
    "\n",
    "# # S.index = np.arange(len(S))\n",
    "\n",
    "# trim off the rather extreme bits\n",
    "S.loc[:, \"ch1\":\"ch3\"] = S.loc[:, \"ch1\":\"ch3\"].mask(S.loc[:, \"ch1\":\"ch3\"].abs() > 0.1)\n",
    "\n",
    "S = S.resample('30s').quantile(0.5)\n",
    "# S = S.resample('2min').mean()\n",
    "\n",
    "print(\"Spruce data loaded! Geoprocessing...\")\n",
    "\n",
    "tree_lat, tree_long = 63.397140, -148.973065\n",
    "\n",
    "# defining the timezone\n",
    "tz = pytz.timezone('US/Alaska')\n",
    "        \n",
    "irradiations = []\n",
    "azimuths = []\n",
    "for idx in S.index:\n",
    "    \n",
    "    print(idx)\n",
    "\n",
    "    aware_idx = tz.localize(idx.to_pydatetime())\n",
    "    alt = pysolar.solar.get_altitude(tree_lat, tree_long, aware_idx)\n",
    "    azi = pysolar.solar.get_azimuth(tree_lat, tree_long, aware_idx)\n",
    "    irr = pysolar.radiation.get_radiation_direct(aware_idx, alt)\n",
    "\n",
    "    S.loc[idx, \"Azi\"] = azi\n",
    "    S.loc[idx, \"Alt\"] = alt\n",
    "    S.loc[idx, \"Irr\"] = irr\n",
    "        \n",
    "# S = S.dropna()\n",
    "# S.loc[S[\"Irr\"] < 500, \"Irr\"] = 500\n",
    "\n",
    "print(\"Geoprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $x_1 = V_1 \\ cos(\\phi_1), y_1 = V_1 \\ sin(\\phi_1), z_1=0$\n",
    "# $x_2 = V_2 \\ cos(\\phi_2), y_2 = V_2 \\ sin(\\phi_2), z_2=0$\n",
    "# $x_3 = V_3 \\ cos(\\phi_3), y_3 = V_3 \\ sin(\\phi_3), z_3=0$\n",
    "# $x_4 = I \\ cos(\\phi_{sun}) sin(\\alpha_{sun}), y_4 = I \\ sin(\\phi_{sun})sin(\\alpha_{sun}), z_4=I cos(\\theta_{sun})$\n",
    "\n",
    "## see [ellipsoidal coordinates](https://en.wikipedia.org/wiki/Ellipsoidal_coordinates)\n",
    "\n",
    "# $c_x = (\\frac{V_1 cos(\\phi_1) + V_2 cos(\\phi_2) + V_3 cos(\\phi_3) + I cos(\\phi_{sun}) sin(\\alpha_{sun})}{4})$\n",
    "# $c_y = (\\frac{V_1 sin(\\phi_1) + V_2 sin(\\phi_2) + V_3 sin(\\phi_3) + I sin(\\phi_{sun})sin(\\alpha_{sun})}{4})$\n",
    "# $c_z = (\\frac{I cos(\\alpha_{sun})}{4})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cos(np.deg2rad(S[\"Alt\"])).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = {\"ch1\":np.deg2rad(285), \n",
    "           \"ch2\":np.deg2rad(12), \n",
    "           \"ch3\":np.deg2rad(140)}\n",
    "\n",
    "S = S.sort_index()\n",
    "\n",
    "s_scale = 1e-4\n",
    "\n",
    "c_x = (S[\"ch1\"]*np.cos(phi[\"ch1\"]) + S[\"ch2\"]*np.cos(phi[\"ch2\"]) +\n",
    "       S[\"ch3\"]*np.cos(phi[\"ch3\"]) +\n",
    "       s_scale*S[\"Irr\"]*np.cos(np.deg2rad(S[\"Azi\"]))*np.sin(np.deg2rad(S[\"Alt\"])))/4\n",
    "\n",
    "c_y = (S[\"ch1\"]*np.sin(phi[\"ch1\"]) + \n",
    "       S[\"ch2\"]*np.sin(phi[\"ch2\"]) +              \n",
    "       S[\"ch3\"]*np.sin(phi[\"ch3\"]) + \n",
    "       s_scale*S[\"Irr\"]*np.sin(np.deg2rad(S[\"Azi\"]))*np.sin(np.deg2rad(S[\"Alt\"])))/4\n",
    "\n",
    "set_screw = 50\n",
    "c_z = (np.cos(np.deg2rad(S[\"Alt\"])))/(4*set_screw)\n",
    "\n",
    "S[\"cx\"] = c_x/c_x.max()\n",
    "S[\"cy\"] = c_y/c_y.max()\n",
    "S[\"cz\"] = c_z/c_z.max()\n",
    "\n",
    "# find \"zeros\" \n",
    "# because Principal Components will likely be centered around (0, 0, 0)\n",
    "S_x0 = (S.cx.max() - S.cx.min())/2\n",
    "S_y0 = (S.cy.max() - S.cy.min())/2\n",
    "S_z0 = (S.cz.max() - S.cz.min())/2\n",
    "\n",
    "S_x0, S_y0, S_z0\n",
    "fader = (256*S[\"Irr\"]/S[\"Irr\"].max()).values.astype('int')\n",
    "\n",
    "# -------- DIAGNOSTIC PLOT -----------\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "plt_dates = dates.date2num(S.index.to_pydatetime())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# ax.scatter(S.cx - S_x0, \n",
    "#            S.cy - S_y0, \n",
    "#            S.cz - S_z0, \n",
    "#            c=fader, alpha=0.1)\n",
    "\n",
    "p = ax.scatter(S.cx, \n",
    "               S.cy, \n",
    "               S.cz, \n",
    "               s=2,\n",
    "               c=fader, alpha=0.1)\n",
    "\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "\n",
    "# ax.view_init(elev=45, azim=30)\n",
    "\n",
    "fig.colorbar(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_path = r\"/home/dax/Documents/ALBUM/SPRUCE/Auditization/2022 10 15 SPRUCE samples.wav\" # silence -60.0\n",
    "# audio_path = r\"/home/dax/Documents/ALBUM/SPRUCE/Auditization/2022 10 27 SPRUCE woodyard hones.wav\" # silence -55.0\n",
    "# audio_path = r\"/home/dax/Documents/ALBUM/SPRUCE/Auditization/2022 10 27 SPRUCE small arms.wav\" # silence -47.2\n",
    "# audio_path = r\"/home/dax/Documents/ALBUM/SPRUCE/Auditization/2022 10 01 butt dome compressed clar.wav\"\n",
    "# audio_path = r\"/home/dax/Documents/ALBUM/SPRUCE/Auditization/2022 10 15 SPRUCE drumsticks.wav\"\n",
    "# audio_path = r\"/media/dax/4/DENAMTVI_2014.wav\"\n",
    "# audio_path = r\"/media/dax/4/_KATMDUPO_2016.wav\"\n",
    "# audio_path = r\"/media/dax/4/DENAUTOK_2019.wav\"\n",
    "# audio_path = '/home/dax/Documents/ALBUM/bux/2022 09 26 water courses/2022 09 26 water courses.wav'\n",
    "# audio_path = '/home/dax/Documents/ALBUM/SPRUCE/2022 11 27 risset.wav'\n",
    "# audio_path = \"/home/dax/Documents/ALBUM/SPRUCE/MIDI_bells.wav\"\n",
    "# audio_path = \"/home/dax/Documents/ALBUM/SPRUCE/MIDI_chip.wav\"\n",
    "# audio_path = \"/home/dax/Documents/ALBUM/SPRUCE/MIDI_voic.wav\"\n",
    "audio_path = \"/home/dax/Documents/ALBUM/SPRUCE/MIDI_star.wav\"\n",
    "\n",
    "save_path = os.path.dirname(audio_path) #r\"/home/dax/Documents/ALBUM/SPRUCE/04 Audio Fabric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"salmon\">$Tape Math$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold(0.36787944231, \"-\", 1)\n",
    "\n",
    "# stereo = interpolate.interp1d([0, 180], [-100, 100])\n",
    "# stereo(12)\n",
    "\n",
    "S = S.dropna()\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4096*2\n",
    "# 1/2.71828182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_chunks, normalized_data, indices_out, clip_pitch = PCA_audio_sampler_prime(audio_path, \n",
    "                                                                   fft_size=2048, \n",
    "                                                                   silence_thresh=-40.0, \n",
    "                                                                   min_silence=1, # int (ms), should be small at first \n",
    "                                                                                   # to let in samples; you can always turn it up\n",
    "                                                                                 \n",
    "                                                                   len_thresh=0.05, # we'd like relatively long samples (ex., ms); \n",
    "                                                                                  #  this will floor the PCA analysis\n",
    "                                                                   \n",
    "                                                                   pad=True,       # this pad should be large (ex. 500 ms), or 'True'\n",
    "                                                                   target_amplitude=None, # headroom (should be large!)\n",
    "                                                                   compute_pitch=False, \n",
    "                                                                   verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lengths = np.array([len(n) for n in normalized_data])\n",
    "\n",
    "# what percentage do we want to preserve?\n",
    "preserve = 20 # % ####################################################### MAIN PARAMETER\n",
    "p = 100 - preserve\n",
    "shortest_vector = int(np.percentile(sample_lengths, p))\n",
    "\n",
    "print(shortest_vector)\n",
    "\n",
    "training_data_raw = []\n",
    "for sample in normalized_data:\n",
    "    if len(sample) > shortest_vector:\n",
    "        training_data_raw.append(sample[:shortest_vector])\n",
    "        \n",
    "training_data = np.vstack(training_data_raw)\n",
    "training_data[training_data == -inf] = 0\n",
    "\n",
    "pca=PCA(n_components=3)\n",
    "pca.fit(training_data)\n",
    "\n",
    "print(pca.explained_variance_ratio_, pca.singular_values_)\n",
    "\n",
    "projected = pca.fit_transform(training_data)\n",
    "\n",
    "# ----------  PLOT THE RESULTS  ------------------\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9,4.8))\n",
    "ax[0].scatter(projected[:, 0], projected[:, 1], s=1, color=\"k\")\n",
    "ax[0].set_xlabel('principle component 1', labelpad=15)\n",
    "ax[0].set_ylabel('principle component 2', labelpad=10)\n",
    "ax[1].scatter(projected[:, 1], projected[:, 2], s=1, color=\"k\")\n",
    "ax[1].set_xlabel('principle component 2', labelpad=15)\n",
    "ax[1].set_ylabel('principle component 3', labelpad=10)\n",
    "\n",
    "x, y = (0, 0)\n",
    "ax[0].axhline(y, color=\"magenta\")\n",
    "ax[0].axvline(x, color=\"magenta\")\n",
    "ax[1].axhline(y, color=\"lime\")\n",
    "ax[1].axvline(x, color=\"lime\")\n",
    "\n",
    "ax[0].set_title(\"PCA on audio clips\", loc=\"left\", fontsize=14, y=1.02)\n",
    "# plt.savefig(r\"C:\\Users\\DBetchkal\\Desktop\\PCA_learning.png\", dpi=100, bbox_inches=\"tight\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log(S[\"Irr\"]).hist()\n",
    "\n",
    "wax = S[\"Irr\"]\n",
    "\n",
    "wax[wax < 500] = 500\n",
    "np.log10(wax).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take $PC_1$, $PC_2$, $PC_3$ and map onto the range of $c_x$, $c_y$, $c_z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the 3D coordinates computed above\n",
    "pathway = S.loc[:, [\"cx\", \"cy\", \"cz\"]].values\n",
    "\n",
    "# find the ranges of all 3D coordinates\n",
    "PC1_min, PC2_min, PC3_min = np.nanmin(projected, axis=0)\n",
    "PC1_max, PC2_max, PC3_max = np.nanmax(projected, axis=0)\n",
    "x_min, y_min, z_min = np.nanmin(pathway, axis=0)\n",
    "x_max, y_max, z_max = np.nanmax(pathway, axis=0)\n",
    "\n",
    "# set up interpolation functions\n",
    "# for eventual sample selection\n",
    "map_x = interpolate.interp1d([x_min, x_max],\n",
    "                             [PC1_min, PC1_max])\n",
    "\n",
    "map_y = interpolate.interp1d([y_min, y_max],\n",
    "                             [PC2_min, PC2_max])\n",
    "\n",
    "map_z = interpolate.interp1d([z_min, z_max],\n",
    "                             [PC3_min, PC3_max])\n",
    "\n",
    "\n",
    "# # set up interpolation functions\n",
    "# # for eventual sample selection\n",
    "# map_x = interpolate.interp1d([x_min, x_max],\n",
    "#                              [-25, 40])\n",
    "\n",
    "# map_y = interpolate.interp1d([y_min, y_max],\n",
    "#                              [12, -15])\n",
    "\n",
    "# map_z = interpolate.interp1d([z_min, z_max],\n",
    "#                              [-12, 14])\n",
    "\n",
    "how_far_apart = 10 # steps\n",
    "audio_out = AudioSegment.empty()\n",
    "sample_number = []\n",
    "for step in pathway[::how_far_apart, :]:\n",
    "    \n",
    "    print(\"c_x, c_y, c_z:\", step)\n",
    "    \n",
    "    selector = np.array([map_x(step[0]),\n",
    "                         map_y(step[1]),\n",
    "                         map_z(step[2])])\n",
    "    \n",
    "    dist_ind = np.sqrt(np.sum((projected-selector)**2, axis=1))\n",
    "    \n",
    "    sample_idx = np.argmin(dist_ind)\n",
    "    sample_number.append(sample_idx)\n",
    "    print(\"\\twhich corresponds to sample\", sample_idx)\n",
    "    if(sample_idx != 0):\n",
    "        \n",
    "        selected_sample = audio_chunks[sample_idx]\n",
    "        dur = selected_sample.duration_seconds\n",
    "        sample = selected_sample.fade_in(dur/10).fade_out(dur/5)\n",
    "        audio_out = audio_out + sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S[\"sample_idx\"] = sample_number\n",
    "# plt.figure(figsize=(14, 1))\n",
    "# plt.plot(S.index, S[\"sample_idx\"], ls=\"-\", lw=0.5, marker=\"o\", ms=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datetimes as strings\n",
    "startdt_out, enddt_out = [dt.datetime.strftime(t, \"%Y%m%d_%H%M%S\") for t in [S.index.min(), S.index.max()]]\n",
    "\n",
    "# get the site\n",
    "site = \"SPRUCE\"\n",
    "\n",
    "# version\n",
    "v = \"_3_13_3\"\n",
    "\n",
    "filename = site + \" begin \" + startdt_out + \" end \" + enddt_out + \" v\" + str(v) + \".wav\"\n",
    "audio_out.export(save_path + os.sep + filename, format=\"wav\")\n",
    "\n",
    "audio_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(S.index, S[\"cx\"], ls=\"\", marker=\"o\", color=\"r\", ms=2)\n",
    "plt.plot(S.index, S[\"cy\"], ls=\"\", marker=\"o\", color=\"g\", ms=2)\n",
    "plt.plot(S.index, S[\"cz\"], ls=\"\", marker=\"o\", color=\"b\", ms=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_point_and_distance(p, a, b):\n",
    "    s = b - a\n",
    "    w = p - a\n",
    "    ps = np.dot(w, s)\n",
    "    if ps <= 0:\n",
    "        return a, np.linalg.norm(w)\n",
    "    l2 = np.dot(s, s)\n",
    "    if ps >= l2:\n",
    "        closest = b\n",
    "    else:\n",
    "        closest = a + ps / l2 * s\n",
    "    return closest, np.linalg.norm(p - closest)\n",
    "\n",
    "\n",
    "point = [0, 0, 0]\n",
    "seg = [[1, 1, 1], [1e3, 1e3, 1e3]] # the point of interest and a much larger value\n",
    "closest_point_and_distance(point, np.array(seg[0]), np.array(seg[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(S):\n",
    "    \n",
    "    phi = {\"ch1\":np.deg2rad(285), \n",
    "           \"ch2\":np.deg2rad(12), \n",
    "           \"ch3\":np.deg2rad(140)}\n",
    "    \n",
    "    for idx, row in S.iterrows():\n",
    "        \n",
    "        c_x = \n",
    "        c_y = (S[\"ch1\"]*np.sin(phi[\"ch1\"]) + S[\"ch2\"]*np.sin(phi[\"ch2\"]) + S[\"ch2\"]*np.sin(phi[\"ch2\"]) + )/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S.dropna()\n",
    "\n",
    "dir_dict = {2:12, 3:140, 1:285}\n",
    "color_dict = {1:\"red\", 2:\"green\", 3:\"blue\"}\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 5.5), sharex=True)\n",
    "\n",
    "for channel in np.arange(3):\n",
    "\n",
    "    ax[channel].plot(S[\"Azimuth\"], S[\"ch\"+str(channel+1)], ls=\"\", marker=\"o\", ms=1, color=color_dict[channel+1])\n",
    "    ax[channel].axvline(dir_dict[channel+1], color=\"magenta\", zorder=1)\n",
    "#     ax[channel].set_ylim(S.loc[:, \"ch1\":\"ch3\"].min().min() - 0.05, \n",
    "#                          S.loc[:, \"ch1\":\"ch3\"].max().max() + 0.05)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Sun Azimuth (°)\", labelpad=20, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa = S.dropna()\n",
    "channel = 1\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "plt_dates = dates.date2num(S.index.to_pydatetime())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.plot(plt_dates, 1000*wa[\"ch\"+str(channel)], wa[\"Irradiation\"], \n",
    "        color=\"k\", ls=\"\", ms=1, marker=\"o\", alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Sun Azimuth (°)\")\n",
    "ax.set_ylabel(\"Voltage (mV)\")\n",
    "ax.set_zlabel(\"Solar Irradiation (W)\")\n",
    "\n",
    "# ax.view_init(elev=45, azim=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"interior angles\", \"\\n\\n\", \n",
    "      \"from 1 to 2:\", str((360-285)+12)+\"°\\n\",\n",
    "      \"from 2 to 3:\", str(140-12)+\"°\\n\",\n",
    "      \"from 3 to 1:\", str(285-140)+\"°\\n\")\n",
    "\n",
    "print(87+128+145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = dt.datetime.strftime(S.index.min(), \"%Y %m %d\") + \" \" + \"ALL\"\n",
    "# title = \"ALL MEASUREMENTS TOGETHER\"\n",
    "\n",
    "S = S.loc[S[\"tree\"] == 'CantwellRock 001']\n",
    "\n",
    "title = \"Cantwell Rock TOGETHER\"\n",
    "linesPerSave = 250\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(14, 5), sharex=True)\n",
    "ax[0].plot(S.index, 1000*S[\"ch1\"], \n",
    "           color=\"red\", ls=\"\", marker=\"o\", ms=1, label=dir_dict[\"ch1\"])\n",
    "ax[0].plot(S.index, 1000*S[\"ch2\"], \n",
    "           color=\"green\", ls=\"\", marker=\"o\", ms=1, label=dir_dict[\"ch2\"])\n",
    "ax[0].plot(S.index, 1000*S[\"ch3\"], \n",
    "           color=\"blue\", ls=\"\", marker=\"o\", ms=1, label=dir_dict[\"ch3\"])\n",
    "ax[0].set_title(title, fontsize=14, loc=\"left\", y=1.05)\n",
    "\n",
    "ax[0].set_ylabel(\"Voltage (mV)\", labelpad=20, fontsize=12)\n",
    "ax[0].xaxis.set_major_formatter(mdates.DateFormatter(\"%m %d\\n%H:%M\"))\n",
    "\n",
    "ax[0].axhline(0, ls=\"--\", color=\"gray\", zorder=20)\n",
    "\n",
    "ax[0].legend(bbox_to_anchor=(1.01, 0.5))\n",
    "ax[0].set_ylim(-200, 200)\n",
    "\n",
    "# time_series = time_series.loc[S.index.min():S.index.max()]\n",
    "# ax[1].plot(time_series.index, time_series[\"t, 2m\"], \n",
    "#            color=\"k\", ls=\"-\", label=\"temp C\")\n",
    "\n",
    "# # draw the \n",
    "# for i in np.arange(0, len(S), linesPerSave):\n",
    "#     ax.axvline(S.iloc[i, :].name, color=\"red\", ls=\"--\", alpha=0.1, zorder=2)\n",
    "\n",
    "# plt.savefig(r\"/home/dax/Documents/ALBUM/Spruce/Field Testing\" + os.sep + title + \".png\",\n",
    "#             dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "\n",
    "# ax.set_xlim(S.index.min(), S.index.min()+dt.timedelta(minutes=20))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dt.datetime.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_clip = \"2022-08-17 00:00:00\"\n",
    "# plt.plot(S.loc[start_clip:, \"ch1\"], time_series[start_clip:])\n",
    "\n",
    "S.index = S.index.to_series().apply(lambda t: t.replace(microsecond=0))\n",
    "\n",
    "J = time_series.merge(S, how=\"inner\", left_index=True, right_index=True)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(1000*J[\"ch1\"], \n",
    "         1000*J[\"t, 2m\"], \n",
    "         ls=\"\", ms=1, marker=\"o\", alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clip = \"2022-08-17 00:00:00\"\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(1000*S.loc[start_clip:, \"ch1\"], \n",
    "         1000*S.loc[start_clip:, \"ch2\"], \n",
    "         ls=\"\", ms=1, marker=\"o\", color=\"k\", alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[\"Hour\"] = S.index.to_series().dt.hour\n",
    "\n",
    "hourly = np.array([(hr, np.nanpercentile(group.loc[:, [\"ch1\", \"ch2\", \"ch3\"]], 50, axis=0)) for hr, group in S.groupby(\"Hour\")])\n",
    "hours, medians = hourly.T\n",
    "\n",
    "channels = pd.DataFrame([list(p) for p in medians], columns=[\"ch1\", \"ch2\", \"ch3\"])\n",
    "plt.plot(channels.index.astype('int'), channels[\"ch1\"], label=\"ch1\", color=\"red\")\n",
    "plt.plot(channels.index.astype('int'), channels[\"ch2\"], label=\"ch2\", color=\"green\")\n",
    "plt.plot(channels.index.astype('int'), channels[\"ch3\"], label=\"ch3\", color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(S.loc[:, [\"ch1\", \"ch2\", \"ch3\"]], 50, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 30 # mins\n",
    "time_steps = np.arange(S.index.min(), S.index.max(), dt.timedelta(minutes=step))\n",
    "\n",
    "\n",
    "for i, time_step in enumerate(time_steps):\n",
    "    \n",
    "    ts = pd.to_datetime(time_step)\n",
    "    y_max = S.max()[:3].max()\n",
    "#     y_max = 0.02\n",
    "#     y_max = 0.1\n",
    "    y_min = S.min()[:3].min()\n",
    "#     y_min = 0.0\n",
    "    \n",
    "    fig, ax = plt.subplots(3, 1, figsize=(12, 3), sharex=True)\n",
    "    ax[0].plot(S.loc[ts:ts+dt.timedelta(minutes=step), \"ch1\"], lw=0.5, color=\"red\")\n",
    "    ax[1].plot(S.loc[ts:ts+dt.timedelta(minutes=step), \"ch2\"], lw=0.5, color=\"green\")\n",
    "    ax[2].plot(S.loc[ts:ts+dt.timedelta(minutes=step), \"ch3\"], lw=0.5, color=\"blue\")\n",
    "    \n",
    "    for a in ax:\n",
    "        a.set_ylim([y_min, y_max])\n",
    "        a.xaxis.set_major_formatter(mdates.DateFormatter(\"%m %d\\n%H:%M:%S\"))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating a responsive plot\n",
    "# %matplotlib widget\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "step = 50\n",
    "\n",
    "color_dict = {\"BlueHome 001\":\"blue\", \"BlueHome 002\":\"blue\", \"BlueHome 003\":\"navy\",\n",
    "              \"Brushkana 001\":\"orange\", \"Brushkana 003\":\"salmon\",\n",
    "              \"CantwellRock 001\":\"k\", \"DenaliHQ 001\":\"green\"}\n",
    "\n",
    "for tree, obs in S.groupby(\"tree\"):\n",
    "\n",
    "    ax.plot(obs[\"ch1\"][::step], obs[\"ch2\"][::step], obs[\"ch3\"][::step], \n",
    "            color=color_dict[tree], ls=\"\", ms=1, marker=\"o\", alpha=0.5)\n",
    "ax.view_init(elev=45, azim=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rate = 44100\n",
    "fft_size = 512\n",
    "\n",
    "# perform a short-time Fourier transform on the data\n",
    "frequencies, times, Zxx = signal.stft(S[\"ch2\"], \n",
    "                                      rate, \n",
    "                                      nfft=fft_size)\n",
    "\n",
    "spectrogram = np.log(np.abs(Zxx))\n",
    "\n",
    "plt.figure(figsize=(10, 1))\n",
    "plt.pcolormesh(times, frequencies, spectrogram, cmap='magma')\n",
    "plt.title(\"Spectrogram Representation\", loc=\"left\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(save):\n",
    "#     print(workingDir+os.sep+titleBar+\".wav\")\n",
    "\n",
    "#     signal_to_wav((out_data).astype('int'), \n",
    "#                   workingDir+os.sep+titleBar+\".wav\", \n",
    "#                   playback_rate)\n",
    "\n",
    "playback_rate = 11000\n",
    "IPython.display.Audio(S[\"ch3\"], rate=playback_rate)\n",
    "\n",
    "# playback_rate = 10000\n",
    "\n",
    "# for col in S:\n",
    "#     if len(col) == 3:\n",
    "        \n",
    "#         out_filename = os.path.dirname(meas) + os.sep + os.path.basename(meas)[:-4] + \"_\" + col + \"_audio_\" + str(playback_rate) + \"Hz.wav\"\n",
    "#         signal_to_wav((10000*(S[col]/S[col].max())).astype('int'),\n",
    "#                       out_filename,\n",
    "#                       playback_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
